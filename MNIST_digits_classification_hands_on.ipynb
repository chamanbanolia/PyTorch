{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Welocome to your first hands-on on PyTorch\n",
    "#### In this hands-on you will be building a feed forward network using PyTorch to identify digits from the image.\n",
    "#### Follow the instructions provided for each cell and code accordingly\n",
    "#### Once you write the code in each cell make sure you run the cell by hitting **shift + enter**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make sure to run the below two cells "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-02-21 17:06:33--  http://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
      "Resolving www.di.ens.fr (www.di.ens.fr)... 129.199.99.14\n",
      "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://www.di.ens.fr/~lelarge/MNIST.tar.gz [following]\n",
      "--2023-02-21 17:06:33--  https://www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
      "Connecting to www.di.ens.fr (www.di.ens.fr)|129.199.99.14|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [application/x-gzip]\n",
      "Saving to: ‘MNIST.tar.gz.1’\n",
      "\n",
      "MNIST.tar.gz.1          [              <=>   ]  33.20M  10.9MB/s    in 3.1s    \n",
      "\n",
      "2023-02-21 17:06:37 (10.9 MB/s) - ‘MNIST.tar.gz.1’ saved [34813078]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget www.di.ens.fr/~lelarge/MNIST.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MNIST/\n",
      "MNIST/raw/\n",
      "MNIST/raw/train-labels-idx1-ubyte\n",
      "MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "MNIST/raw/t10k-labels-idx1-ubyte\n",
      "MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "MNIST/raw/train-images-idx3-ubyte\n",
      "MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "MNIST/raw/t10k-images-idx3-ubyte\n",
      "MNIST/raw/train-images-idx3-ubyte.gz\n",
      "MNIST/processed/\n",
      "MNIST/processed/training.pt\n",
      "MNIST/processed/test.pt\n"
     ]
    }
   ],
   "source": [
    "!tar -zxvf MNIST.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Download the dataset\n",
    "- use **MNIST** from **torchvision.datasets** to download the MNIST digits dataset. Make sure the downladed tensors are tansormed to Tensors.\n",
    "- Genearte train and test loaders of batch size 64 and assign it to variables **trainloader** and **testloader** respectively.\n",
    "\n",
    "#### Expected output:\n",
    "    dimension of first batch of trainloader: torch.Size([64, 1, 28, 28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dimension of first batch of trainloader: torch.Size([64, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from torch import optim\n",
    "import helper\n",
    "\n",
    "\n",
    "# Download and load the training data\n",
    "trainset = MNIST(root='./data',  train=True, transform=transforms.ToTensor(), download=True)             ###download trainset\n",
    "testset = MNIST(root='./data',  train=False, transform=transforms.ToTensor(), download=True)              ###download testset\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)\n",
    "\n",
    "\n",
    "image, labels = next(iter(trainloader))\n",
    "print(\"dimension of first batch of trainloader:\", image.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "- define the method named model_buid() to build a sequential model.\n",
    "  - parameters: \n",
    "       - **input_size** int: number of input features  \n",
    "       - **hidden_sizes** array of size 3: array of number of nodes in each of the three hidden layers  \n",
    "       - **output int**: number of nodes at output layer (or number of classes to classify)  \n",
    "  - returns model: sequential model  \n",
    "Apply relu activation between each layer and for the **final layer out apply logSoftmax.**  \n",
    "Logsoftmax log transformation of softmax output which is given by :$$\n",
    " \\sigma(x_i) =  \\log \\cfrac{e^{x_i}}{\\sum_{k=1}^{N}{e^{x_k}}}$$ where N is the number of classes  \n",
    " more information [here](https://pytorch.org/docs/stable/nn.html#torch.nn.LogSoftmax) \n",
    "  - using the function you defined, **initilize the model to have input size 784, three hidden layers to have 256, 128 and 64 nodes and finally an output layer of size 10 nodes.**\n",
    "  \n",
    "#### Expected output:  \n",
    "Sequential(  \n",
    "  (0): Linear(in_features=784, out_features=256, bias=True)  \n",
    "  (1): ReLU()  \n",
    "  (2): Linear(in_features=256, out_features=128, bias=True)  \n",
    "  (3): ReLU()  \n",
    "  (4): Linear(in_features=128, out_features=64, bias=True)  \n",
    "  (5): ReLU()  \n",
    "  (6): Linear(in_features=64, out_features=10, bias=True)  \n",
    "  (7): LogSoftmax()  \n",
    ")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (7): LogSoftmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(999)\n",
    "input_size = 784\n",
    "hidden_sizes = [256,128, 64]\n",
    "output_size = 10\n",
    "\n",
    "# Build a feed-forward network\n",
    "def build_model(input_size, hidden_sizes, output_size):\n",
    "    ####Start code here\n",
    "    \n",
    "    #model = Network(input_size, hidden_sizes, output_size)\n",
    "    model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),  \n",
    "                   nn.ReLU(),\n",
    "                   nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                   nn.ReLU(),\n",
    "                   nn.Linear(hidden_sizes[1], hidden_sizes[2]),\n",
    "                   nn.ReLU(),\n",
    "                   nn.Linear(hidden_sizes[2], output_size),\n",
    "                   nn.LogSoftmax(dim=1)\n",
    "                   )\n",
    "    #### End code\n",
    "    return model\n",
    "\n",
    "classifier = build_model(input_size, hidden_sizes, output_size)\n",
    "print(classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 : Perform forward pass on single image\n",
    "- get the images and labels from first batch of trainloader\n",
    "- sample the first image from the batch and flatten the image tensor from (1 x 28 x 28) to (1, 784)\n",
    "- using the model you defined in the previous cell perfrom a forward pass on the flattened image and save the network output to variable **log_ps**\n",
    "- transform log transformed softmax output log_ps to exponential and assign it to ps (hint use torch.exp())\n",
    "- return the top probability and its index from  **ps** (hint: use ps.topk())  \n",
    "Since the model is not trained, yet the output class probabilities are uniform.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0959, 0.0976, 0.0963, 0.1030, 0.0904, 0.1082, 0.0989, 0.1100, 0.0972,\n",
      "         0.1026]])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.manual_seed(999)\n",
    "####Start code here\n",
    "images, labels = iter(trainloader).next()\n",
    "#print(images.size(), labels.size())\n",
    "image = images[0,:,:,:]                   ###sample first image from images\n",
    "image = image.resize_(1,784)                  ###flatten the image\n",
    "\n",
    "with torch.no_grad():\n",
    "    log_ps = classifier.forward(image)\n",
    "ps = torch.exp(log_ps)\n",
    "print(ps)\n",
    "top_p, top_class = torch.topk(ps,1)\n",
    "###End code\n",
    "\n",
    "helper.view_classify(image.view(1,28,28), ps)\n",
    "prob = top_p.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4   Define criterain (loss function) and optimizer\n",
    "  - Define criterian to be [negetive likelihood loss](https://pytorch.org/docs/stable/nn.html#torch.nn.NLLLoss) since the network output is log transformed probabilities. (hint: use nn.NLLLoss())\n",
    "  - Define optimizer to be [Adam](https://pytorch.org/docs/stable/optim.html#torch.optim.Adam) and set learning rate to 0.003 and pass the parameters of **classifier** model (hint: use optim.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Start code here\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(params = classifier.parameters(), lr=0.003)\n",
    "####End code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5 Train the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5..  Training Loss: 0.107..  Test Loss: 0.145..  Test Accuracy: 0.961\n",
      "Epoch: 2/5..  Training Loss: 0.080..  Test Loss: 0.093..  Test Accuracy: 0.974\n",
      "Epoch: 3/5..  Training Loss: 0.063..  Test Loss: 0.083..  Test Accuracy: 0.974\n",
      "Epoch: 4/5..  Training Loss: 0.052..  Test Loss: 0.090..  Test Accuracy: 0.977\n",
      "Epoch: 5/5..  Training Loss: 0.047..  Test Loss: 0.092..  Test Accuracy: 0.976\n",
      "After training\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.manual_seed(999)\n",
    "\n",
    "epochs = 5\n",
    "steps = 0\n",
    "\n",
    "\n",
    "for e in range(epochs):\n",
    "    \n",
    "    ###Initializing loss\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        ###Start code here\n",
    "        images = images.view(images.shape[0], -1)   ###flatten the images\n",
    "        optimizer.zero_grad()   \n",
    "        \n",
    "        output = classifier.forward(images)         ###perform forward pass\n",
    "        loss = criterion(output, labels)            ### comput loss using the criterion by passing log_ps and labels\n",
    "        loss.backward()                             #### call .backward() on loss\n",
    "        optimizer.step()                            #### update parameters using .step() on optimizer\n",
    "        \n",
    "        \n",
    "        ###End code\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        \n",
    "    else:\n",
    "         # Compute loss on test set for each batch of training\n",
    "        ###Initializing train loss and test loss\n",
    "        test_loss = 0\n",
    "        accuracy = 0\n",
    "        \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in testloader:\n",
    "                ###Start code here\n",
    "                images = images.view(images.shape[0], -1)      ### flatten images\n",
    "                log_ps = classifier.forward(images)            ###perform forward pass\n",
    "                test_loss += criterion(log_ps, labels)         ### update the test loss    \n",
    "                             \n",
    "                ps = torch.exp(log_ps)                         ### transform log_ps to exponential          \n",
    "                top_p, top_class = torch.topk(ps,1)            ### get the top class for each sample\n",
    "                ####End code\n",
    "                \n",
    "                equals = top_class == labels.view(*top_class.shape)\n",
    "                accuracy += torch.mean(equals.type(torch.FloatTensor))\n",
    "\n",
    "        \n",
    "\n",
    "        print(\"Epoch: {}/{}.. \".format(e+1, epochs),\n",
    "              \"Training Loss: {:.3f}.. \".format(running_loss/len(trainloader)),\n",
    "              \"Test Loss: {:.3f}.. \".format(test_loss/len(testloader)),\n",
    "              \"Test Accuracy: {:.3f}\".format(accuracy/len(testloader)))\n",
    "print(\"After training\")\n",
    "helper.view_classify(images[0].view(1,28,28), ps[0])\n",
    "with open(\"output.txt\", \"w\") as file:\n",
    "    file.write(\"{:.2f}\".format(prob)+\"\\n\")\n",
    "    file.write((\"{:.2f}\".format(running_loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
